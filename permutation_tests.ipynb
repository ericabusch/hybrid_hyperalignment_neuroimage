{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,glob\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from scipy.stats import percentileofscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average final results across data folds\n",
    "goes from (n_runs, n_subjects, n_features) -> (n_subjects, n_features)\n",
    "and we can average across features to get an average value (barplots) or across subjects to get a feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d0c1aea69663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrha_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../response_hyper/{}/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"dense\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"vertex_isc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"clf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0moutfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../final_results/{}/rha_{}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrha_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fold*\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"*{}*.npy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmetric_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "for dataset in ['budapest','raiders','whiplash']:\n",
    "    rha_dir = '../../response_hyper/{}/'.format(dataset)\n",
    "    for metric in [\"dense\",\"vertex_isc\",\"clf\"]:\n",
    "        outfn = os.path.join('../final_results/{}/rha_{}.npy'.format(dataset,metric))\n",
    "        g = glob.glob(os.path.join(rha_dir, \"fold*\",\"results\",\"*{}*.npy\".format(metric)))\n",
    "        metric_results = np.stack([np.load(b) for b in g])\n",
    "        avg_result = np.mean(metric_results, axis=0)\n",
    "        np.save(outfn, avg_result)\n",
    "\n",
    "    cha_dir = '../../conn_hyper/{}/'.format(dataset)\n",
    "    for metric in [\"dense\",\"vertex_isc\",\"clf\"]:\n",
    "        outfn = os.path.join('../final_results/{}/cha_{}.npy'.format(dataset,metric))\n",
    "        g = glob.glob(os.path.join(cha_dir, \"fold*\",\"results\",\"*{}*.npy\".format(metric)))\n",
    "        metric_results = np.stack([np.load(b) for b in g])\n",
    "        avg_result = np.mean(metric_results, axis=0)\n",
    "        np.save(outfn, avg_result)\n",
    "\n",
    "    h2a_dir = '../../response_hyper/{}/'.format(dataset)\n",
    "    for metric in [\"dense\",\"vertex_isc\",\"clf\"]:\n",
    "        outfn = os.path.join('../final_results/{}/h2a_{}.npy'.format(dataset,metric))\n",
    "        g = glob.glob(os.path.join(h2a_dir, \"fold*\",\"results\",\"*{}*.npy\".format(metric)))\n",
    "        metric_results = np.stack([np.load(b) for b in g])\n",
    "        avg_result = np.mean(metric_results, axis=0)\n",
    "        np.save(outfn, avg_result)\n",
    "\n",
    "    aa_dir = '../../response_hyper/{}/'.format(dataset)\n",
    "    for metric in [\"dense\",\"vertex_isc\",\"clf\"]:\n",
    "        outfn = os.path.join('../final_results/{}/aa_{}.npy'.format(dataset,metric))\n",
    "        g = glob.glob(os.path.join(aa_dir, \"fold*\",\"results\",\"*{}*.npy\".format(metric)))\n",
    "        metric_results = np.stack([np.load(b) for b in g])\n",
    "        avg_result = np.mean(metric_results, axis=0)\n",
    "        np.save(outfn, avg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {'dataset':[],'metric':[],'comparison':[],'pvalue':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed_difference = model1_metricA - model2_metricA\n",
    "def permutation_test(observed_difference, n_iterations):\n",
    "    obtained_mean = observed_difference.mean()\n",
    "    null_distribution_of_means = np.ndarray((n_iterations))\n",
    "    # flip sign permutation test\n",
    "    for i in range(n_iterations):\n",
    "        weights = [random.choice([1,-1]) for d in range(len(observed_difference))]\n",
    "        null_distribution_of_means[i]=(weights * observed_difference).mean()\n",
    "    percentile = percentileofscore(null_distribution_of_means, obtained_mean)\n",
    "    return percentile # this returns the percentile of obtained score versus the null distribution\n",
    "# of scores. Then we compute the pvalue depending upon if it's a 1 tailed or 2 tailed value.\n",
    "\n",
    "def run_permutations(data, n_iterations):\n",
    "    pvalues = {}\n",
    "    combos = combinations(data.keys(),2) \n",
    "    for combo in combos:\n",
    "        combo_label = str(combo[0])+'_'+str(combo[1])\n",
    "        obtained_difference = data[combo[0]] - data[combo[1]]\n",
    "        percentile = permutation_test(obtained_difference, n_iterations)\n",
    "        if (obtained_difference>0).sum() < 20:\n",
    "            percentile=100.-percentile\n",
    "        pvalues[combo_label] = (100.-percentile)/100.\n",
    "    return pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budapest significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "budapest_results = '../../final_results/budapest/'\n",
    "isc={}\n",
    "for A in ['aa','cha','rha','h2a']:\n",
    "    isc[A] = np.mean(np.nan_to_num(np.load(os.path.join(budapest_results, '{A}_vertex_isc.npy'.format(A=A)))),axis=0)\n",
    "\n",
    "clf={}\n",
    "for A in ['aa','cha','rha','h2a']:\n",
    "    clf[A] = np.mean(np.nan_to_num(np.load(os.path.join(budapest_results, '{A}_clf.npy'.format(A=A)))),axis=1)\n",
    "\n",
    "cnx={}\n",
    "for A in ['aa','cha','rha','h2a']:\n",
    "    cnx[A] = np.mean(np.nan_to_num(np.load(os.path.join(budapest_results, '{A}_cnx_isc.npy'.format(A=A)))),axis=0)\n",
    "\n",
    "isc_p, clf_p, cnx_p = [run_permutations(d, 10000) for d in [isc,clf, cnx]]\n",
    "for d,typ in zip([isc_p,clf_p,cnx_p],['isc','clf','cnx']):\n",
    "    for key in d.keys():\n",
    "        results_dict['dataset'].append('budapest')\n",
    "        results_dict['metric'].append(typ)\n",
    "        results_dict['comparison'].append(key)\n",
    "         # these are always one-sided because we expect HA to outperform AA\n",
    "        if 'aa' in key:\n",
    "            d[key]=2*d[key]\n",
    "        results_dict['pvalue'].append(d[key])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raiders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = '../../final_results/raiders/'\n",
    "isc={}\n",
    "for A in ['aa','cha','rha','h2a']:\n",
    "    isc[A] = np.mean(np.nan_to_num(np.load(os.path.join(results, '{A}_vertex_isc.npy'.format(A=A)))),axis=0)\n",
    "\n",
    "clf={}\n",
    "for A in ['aa','cha','rha','h2a']:\n",
    "    clf[A] = np.mean(np.nan_to_num(np.load(os.path.join(results, '{A}_clf.npy'.format(A=A)))),axis=1)\n",
    "\n",
    "cnx={}\n",
    "for A in ['aa','cha','rha','h2a']:\n",
    "    cnx[A] = np.mean(np.nan_to_num(np.load(os.path.join(results, '{A}_cnx_isc.npy'.format(A=A)))),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_p, clf_p, cnx_p = [run_permutations(d, 10000) for d in [isc,clf, cnx]]\n",
    "for d,typ in zip([isc_p,clf_p,cnx_p],['isc','clf','cnx']):\n",
    "    for key in d.keys():\n",
    "        results_dict['dataset'].append('raiders')\n",
    "        results_dict['metric'].append(typ)\n",
    "        results_dict['comparison'].append(key)\n",
    "         # these are always one-sided because we expect HA to outperform AA\n",
    "        if 'aa' in key:\n",
    "            d[key]=2*d[key]\n",
    "        results_dict['pvalue'].append(d[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whiplash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = '../../final_results/whiplash/'\n",
    "isc={}\n",
    "for A in ['aa','cha','rha','h2a']:\n",
    "    isc[A] = np.mean(np.nan_to_num(np.load(os.path.join(results, '{A}_vertex_isc.npy'.format(A=A)))),axis=0)\n",
    "\n",
    "clf={}\n",
    "for A in ['aa','cha','rha','h2a']:\n",
    "    clf[A] = np.mean(np.nan_to_num(np.load(os.path.join(results, '{A}_clf.npy'.format(A=A)))),axis=1)\n",
    "clf['aa'] = np.mean(np.nan_to_num(np.load(os.path.join(results, '{A}_clf.npy'.format(A='aa')))),axis=1)\n",
    "\n",
    "cnx={}\n",
    "for A in ['aa','cha','rha','h2a']:\n",
    "    cnx[A] = np.mean(np.nan_to_num(np.load(os.path.join(results, '{A}_cnx_isc.npy'.format(A=A)))),axis=0)\n",
    "\n",
    "isc_p, clf_p, cnx_p = [run_permutations(d, 10000) for d in [isc,clf,cnx]]\n",
    "for d,typ in zip([isc_p,clf_p,cnx_p],['isc','clf','cnx']):\n",
    "    for key in d.keys():\n",
    "        results_dict['dataset'].append('whiplash')\n",
    "        results_dict['metric'].append(typ)\n",
    "        results_dict['comparison'].append(key)\n",
    "        # these are always one-sided because we expect HA to outperform AA\n",
    "        if 'aa' in key:\n",
    "            d[key]=2*d[key]\n",
    "        results_dict['pvalue'].append(d[key])    \n",
    "    \n",
    "res = pd.DataFrame(results_dict)\n",
    "res.to_csv('../../final_results/significance_all_datasets_final.csv')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
